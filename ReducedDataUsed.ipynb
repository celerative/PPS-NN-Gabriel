{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos las imagenes almacenadas en la carpeta \"images\" con el codigo DataSetReduced y se redimensionan segun img_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import scipy\n",
    "from scipy import misc\n",
    "import numpy as np\n",
    "\n",
    "################ CONSTANTES #################\n",
    "#### modificar en caso que sea necesario ####\n",
    "ruta = './images/' # ruta donde se almacenaron las imagenes creadas con el DataSetReduced.py\n",
    "img_dim= (128, 128) # tamaño de las imagenes redimensionadas\n",
    "\n",
    "# solo es util en caso de que se ejecute el codigo más de 1 vez\n",
    "try:del X\n",
    "except: None\n",
    "try:del Y\n",
    "except: None\n",
    "\n",
    "with open(ruta + 'info.csv', 'r') as info: # informacion de las imagenes\n",
    "    reader = csv.reader(info) # csv parser for annotations file\n",
    "    # lee cada imagen con su clasificacion contenida en el archivo de informacion\n",
    "    for row in reader:\n",
    "        img = plt.imread(ruta + row[0]) # la primera columna es el nombre del archivo\n",
    "        res_img= scipy.misc.imresize(img, img_dim) #redimensiono la imagen\n",
    "        res_img = np.expand_dims(res_img, axis=0) #agrego una dimension para poder aplicar una concatenacion\n",
    "        \n",
    "        #si no esta declarado el arreglo lo crea\n",
    "        try: X = np.append(X, res_img, axis=0)\n",
    "        except: X = np.array(res_img)\n",
    "            \n",
    "        try: Y = np.append(Y, row[1]) # la segunda columna es la clasificacion\n",
    "        except: Y = np.array(row[1])\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se reducen los canales a 1.\n",
    "\n",
    "Keras no tiene una funcion que convierta una imagen RGB en escala de grises. Por lo que se utilizara la libreria numpy para realizar este trabajo.\n",
    "\n",
    "!!Dejar comentado este codigo si se desea utilizar 3 canales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convierte la imagen en escala de grises\n",
    "#try:\n",
    "#    plt.imshow(X[1])\n",
    "#    plt.show()\n",
    "#except: print(\"los valores originales de X ya no estan disponibles :C\")\n",
    "#else:\n",
    "#    X = np.sum(X/3, axis=3, keepdims=True)\n",
    "##squeeze elimina las dimensiones de tamaño 1\n",
    "##ya que matplotlib exige que el canal sea 3 o 4\n",
    "##o que la matriz tenga 2 dimensiones\n",
    "#plt.imshow(np.squeeze(X[1]), cmap='gray')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo siguiente será mezclar las entradas y tomar una parte para el train y otra para el validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "XYtuple = []\n",
    "for i in range(len(X)):\n",
    "    XYtuple.append((X[i], Y[i]))\n",
    "    \n",
    "xx= []\n",
    "yy= []\n",
    "\n",
    "XYtuple = random.sample(XYtuple, len(XYtuple))\n",
    "\n",
    "for i in range(len(XYtuple)):\n",
    "    xx.append(XYtuple[i][0])\n",
    "    yy.append(XYtuple[i][1])\n",
    "\n",
    "X = np.array(xx)\n",
    "Y = np.array(yy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se utilizará el 85% de los datos para entrenar la red, y el 15% para la validacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#85% train 15%test    \n",
    "train_len= (int)(len(X)*0.85)\n",
    "X_train = X[:train_len]\n",
    "Y_train = Y[:train_len]\n",
    "X_valid = X[train_len:]\n",
    "Y_valid = Y[train_len:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "modificamos la forma del arreglo para volverlo categorico\n",
    "Y train es un arreglo unidimensional donde para cada imagen tiene un valor de 1 a 43 segun su clasificacion\n",
    "Y train de salida es un arreglo bidimensional. Donde para cada imagen hay un arreglo de ancho 43 indicando su clasificacion en la posicion correspondiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1110, 43)\n",
      "(196, 43)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "Y_train = np_utils.to_categorical(Y_train, 43)\n",
    "print (Y_train.shape)\n",
    "Y_valid = np_utils.to_categorical(Y_valid, 43)\n",
    "print (Y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocesamiento de imagenes: reescalamiento, corrimiento vertical, corrimiento horizontal, rotacion y estiramiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 images belonging to 43 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 16\n",
    "batch_aug = 50\n",
    "colors= 3\n",
    "#earlystop= EarlyStopping(min_delta= 0.008, patience= 2, verbose=1)\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=2, min_delta = 0.005, verbose=1)\n",
    "nb_train_samples = X_train.shape[0]\n",
    "nb_validation_samples = X_valid.shape[0]\n",
    "\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (colors, img_dim[0], img_dim[1])\n",
    "else:\n",
    "    input_shape = (img_dim[0], img_dim[1], colors)\n",
    "                                      \n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "                                    rotation_range=40,\n",
    "                                    width_shift_range=0.1,\n",
    "                                    height_shift_range=0.1,\n",
    "                                    shear_range=0.2,\n",
    "                                    zoom_range=0.2,\n",
    "                                    fill_mode='nearest')\n",
    "\n",
    "# data augmentation:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow(X_train, Y_train, batch_size=30)\n",
    "\n",
    "validation_generator = test_datagen.flow(X_valid, Y_valid, batch_size=30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codigo de prueba para visualizar la transformacion de las imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data augmentation testing\n",
    "\n",
    "#import keras\n",
    "#from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "#datagen = ImageDataGenerator(\n",
    "#        rotation_range=40,\n",
    "#        width_shift_range=0.1,\n",
    "#        height_shift_range=0.1,\n",
    "#        shear_range=0.2,\n",
    "#        zoom_range=0.2,\n",
    "#        fill_mode='nearest')\n",
    "\n",
    "#x = X_train[1]\n",
    "##x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
    "#x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
    "#print(x.shape)\n",
    "\n",
    "## the .flow() command below generates batches of randomly transformed images\n",
    "## and saves the results to the `augmentation/` directory\n",
    "#i = 0\n",
    "#for batch in datagen.flow(x, batch_size=1,\n",
    "#                          save_to_dir='augmentation', \n",
    "#                          save_prefix='ts', \n",
    "#                          save_format='jpeg'):\n",
    "#    i += 1\n",
    "#    if i > 30:\n",
    "#        break  # luego de 30 imagenes termina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 126, 126, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 61, 61, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1605760   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 43)                5547      \n",
      "=================================================================\n",
      "Total params: 1,639,947\n",
      "Trainable params: 1,639,947\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "69/69 [==============================] - 115s - loss: 3.3692 - acc: 0.1246 - val_loss: 11.9192 - val_acc: 0.2449\n",
      "Epoch 2/20\n",
      "69/69 [==============================] - 94s - loss: 2.7262 - acc: 0.2473 - val_loss: 11.7614 - val_acc: 0.2347\n",
      "Epoch 3/20\n",
      "69/69 [==============================] - 90s - loss: 2.4747 - acc: 0.2894 - val_loss: 11.3016 - val_acc: 0.2908\n",
      "Epoch 4/20\n",
      "69/69 [==============================] - 90s - loss: 2.2196 - acc: 0.3386 - val_loss: 10.4939 - val_acc: 0.3265\n",
      "Epoch 5/20\n",
      "69/69 [==============================] - 89s - loss: 2.0631 - acc: 0.3841 - val_loss: 11.0987 - val_acc: 0.2959\n",
      "Epoch 6/20\n",
      "69/69 [==============================] - 94s - loss: 1.9750 - acc: 0.3971 - val_loss: 10.5270 - val_acc: 0.3163\n",
      "Epoch 7/20\n",
      "69/69 [==============================] - 99s - loss: 1.7961 - acc: 0.4391 - val_loss: 9.8653 - val_acc: 0.3571\n",
      "Epoch 8/20\n",
      "69/69 [==============================] - 110s - loss: 1.6707 - acc: 0.4826 - val_loss: 9.2402 - val_acc: 0.3980\n",
      "Epoch 9/20\n",
      "69/69 [==============================] - 113s - loss: 1.6013 - acc: 0.4986 - val_loss: 8.8668 - val_acc: 0.4388\n",
      "Epoch 10/20\n",
      "69/69 [==============================] - 118s - loss: 1.4898 - acc: 0.5135 - val_loss: 8.8729 - val_acc: 0.4439\n",
      "Epoch 11/20\n",
      "69/69 [==============================] - 109s - loss: 1.3797 - acc: 0.5483 - val_loss: 8.7023 - val_acc: 0.4490\n",
      "Epoch 12/20\n",
      "69/69 [==============================] - 83s - loss: 1.3191 - acc: 0.5676 - val_loss: 8.3100 - val_acc: 0.4541\n",
      "Epoch 13/20\n",
      "69/69 [==============================] - 82s - loss: 1.2385 - acc: 0.5971 - val_loss: 7.4688 - val_acc: 0.5306\n",
      "Epoch 14/20\n",
      "69/69 [==============================] - 88s - loss: 1.2007 - acc: 0.5990 - val_loss: 7.5225 - val_acc: 0.5153\n",
      "Epoch 15/20\n",
      "69/69 [==============================] - 89s - loss: 1.0956 - acc: 0.6386 - val_loss: 7.8737 - val_acc: 0.5051\n",
      "Epoch 16/20\n",
      "69/69 [==============================] - 89s - loss: 1.1145 - acc: 0.6459 - val_loss: 7.0454 - val_acc: 0.5510\n",
      "Epoch 17/20\n",
      "69/69 [==============================] - 88s - loss: 1.0396 - acc: 0.6531 - val_loss: 7.6219 - val_acc: 0.5204\n",
      "Epoch 18/20\n",
      "69/69 [==============================] - 89s - loss: 1.0121 - acc: 0.6546 - val_loss: 7.3450 - val_acc: 0.5357\n",
      "Epoch 19/20\n",
      "69/69 [==============================] - 86s - loss: 0.9968 - acc: 0.6792 - val_loss: 6.3153 - val_acc: 0.5867\n",
      "Epoch 20/20\n",
      "69/69 [==============================] - 86s - loss: 0.9431 - acc: 0.6831 - val_loss: 7.4781 - val_acc: 0.5204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f62ae8986a0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), \n",
    "                 input_shape=input_shape, \n",
    "                 kernel_initializer='glorot_normal', \n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(43, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#model.fit(X_train, Y_train,\n",
    "#            batch_size=batch_size, epochs=epochs,\n",
    "#            verbose=1, validation_data=(X_valid, Y_valid))\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(X_valid, Y_valid),\n",
    "    validation_steps=nb_validation_samples // batch_size,\n",
    "    callbacks = [earlystop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Dicho modelo se fue alterando para realizar diferentes pruebas. Comenzando con una red sencilla de una única capa convolusional y una Fully Connected, y agregandole progresivamente nuevas capas. Los resultados obtenidos fueron muy malos, desde un 5% con la red sencilla y alcanzando un 60% utilizando imagenes en rgb y una red profunda. Debido a esto se decidio cambiar de estrategia y volver a utilizar el dataset completo, tanto de training como de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
